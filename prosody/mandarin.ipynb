{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from pathlib import Path\n",
    "from espnet2.text.phoneme_tokenizer import PhonemeTokenizer\n",
    "from espnet2.text.token_id_converter import TokenIDConverter\n",
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "\n",
    "from prosody.pinyin import *\n",
    "from prosody.en_to_zh import PinyinArpaSpeech, all_tones\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "PWD = %pwd\n",
    "PWD = Path(PWD)\n",
    "LJSPEECH_DIR = (PWD / '../egs2/ljspeech/tts1/').resolve()\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 78\n",
      "encoder self-attention layer type = self-attention\n",
      "encoder self-attention layer type = self-attention\n",
      "Initialize encoder.encoders.0.self_attn.linear_q.bias to zeros\n",
      "Initialize encoder.encoders.0.self_attn.linear_k.bias to zeros\n",
      "Initialize encoder.encoders.0.self_attn.linear_v.bias to zeros\n",
      "Initialize encoder.encoders.0.self_attn.linear_out.bias to zeros\n",
      "Initialize encoder.encoders.0.feed_forward.w_1.bias to zeros\n",
      "Initialize encoder.encoders.0.feed_forward.w_2.bias to zeros\n",
      "Initialize encoder.encoders.0.norm1.bias to zeros\n",
      "Initialize encoder.encoders.0.norm2.bias to zeros\n",
      "Initialize encoder.encoders.1.self_attn.linear_q.bias to zeros\n",
      "Initialize encoder.encoders.1.self_attn.linear_k.bias to zeros\n",
      "Initialize encoder.encoders.1.self_attn.linear_v.bias to zeros\n",
      "Initialize encoder.encoders.1.self_attn.linear_out.bias to zeros\n",
      "Initialize encoder.encoders.1.feed_forward.w_1.bias to zeros\n",
      "Initialize encoder.encoders.1.feed_forward.w_2.bias to zeros\n",
      "Initialize encoder.encoders.1.norm1.bias to zeros\n",
      "Initialize encoder.encoders.1.norm2.bias to zeros\n",
      "Initialize encoder.encoders.2.self_attn.linear_q.bias to zeros\n",
      "Initialize encoder.encoders.2.self_attn.linear_k.bias to zeros\n",
      "Initialize encoder.encoders.2.self_attn.linear_v.bias to zeros\n",
      "Initialize encoder.encoders.2.self_attn.linear_out.bias to zeros\n",
      "Initialize encoder.encoders.2.feed_forward.w_1.bias to zeros\n",
      "Initialize encoder.encoders.2.feed_forward.w_2.bias to zeros\n",
      "Initialize encoder.encoders.2.norm1.bias to zeros\n",
      "Initialize encoder.encoders.2.norm2.bias to zeros\n",
      "Initialize encoder.encoders.3.self_attn.linear_q.bias to zeros\n",
      "Initialize encoder.encoders.3.self_attn.linear_k.bias to zeros\n",
      "Initialize encoder.encoders.3.self_attn.linear_v.bias to zeros\n",
      "Initialize encoder.encoders.3.self_attn.linear_out.bias to zeros\n",
      "Initialize encoder.encoders.3.feed_forward.w_1.bias to zeros\n",
      "Initialize encoder.encoders.3.feed_forward.w_2.bias to zeros\n",
      "Initialize encoder.encoders.3.norm1.bias to zeros\n",
      "Initialize encoder.encoders.3.norm2.bias to zeros\n",
      "Initialize encoder.after_norm.bias to zeros\n",
      "Initialize duration_predictor.conv.0.0.bias to zeros\n",
      "Initialize duration_predictor.conv.0.2.bias to zeros\n",
      "Initialize duration_predictor.conv.1.0.bias to zeros\n",
      "Initialize duration_predictor.conv.1.2.bias to zeros\n",
      "Initialize duration_predictor.linear.bias to zeros\n",
      "Initialize pitch_predictor.conv.0.0.bias to zeros\n",
      "Initialize pitch_predictor.conv.0.2.bias to zeros\n",
      "Initialize pitch_predictor.conv.1.0.bias to zeros\n",
      "Initialize pitch_predictor.conv.1.2.bias to zeros\n",
      "Initialize pitch_predictor.conv.2.0.bias to zeros\n",
      "Initialize pitch_predictor.conv.2.2.bias to zeros\n",
      "Initialize pitch_predictor.conv.3.0.bias to zeros\n",
      "Initialize pitch_predictor.conv.3.2.bias to zeros\n",
      "Initialize pitch_predictor.conv.4.0.bias to zeros\n",
      "Initialize pitch_predictor.conv.4.2.bias to zeros\n",
      "Initialize pitch_predictor.linear.bias to zeros\n",
      "Initialize pitch_embed.0.bias to zeros\n",
      "Initialize energy_predictor.conv.0.0.bias to zeros\n",
      "Initialize energy_predictor.conv.0.2.bias to zeros\n",
      "Initialize energy_predictor.conv.1.0.bias to zeros\n",
      "Initialize energy_predictor.conv.1.2.bias to zeros\n",
      "Initialize energy_predictor.linear.bias to zeros\n",
      "Initialize energy_embed.0.bias to zeros\n",
      "Initialize alignment_module.t_conv1.bias to zeros\n",
      "Initialize alignment_module.t_conv2.bias to zeros\n",
      "Initialize alignment_module.f_conv1.bias to zeros\n",
      "Initialize alignment_module.f_conv2.bias to zeros\n",
      "Initialize alignment_module.f_conv3.bias to zeros\n",
      "Initialize decoder.encoders.0.self_attn.linear_q.bias to zeros\n",
      "Initialize decoder.encoders.0.self_attn.linear_k.bias to zeros\n",
      "Initialize decoder.encoders.0.self_attn.linear_v.bias to zeros\n",
      "Initialize decoder.encoders.0.self_attn.linear_out.bias to zeros\n",
      "Initialize decoder.encoders.0.feed_forward.w_1.bias to zeros\n",
      "Initialize decoder.encoders.0.feed_forward.w_2.bias to zeros\n",
      "Initialize decoder.encoders.0.norm1.bias to zeros\n",
      "Initialize decoder.encoders.0.norm2.bias to zeros\n",
      "Initialize decoder.encoders.1.self_attn.linear_q.bias to zeros\n",
      "Initialize decoder.encoders.1.self_attn.linear_k.bias to zeros\n",
      "Initialize decoder.encoders.1.self_attn.linear_v.bias to zeros\n",
      "Initialize decoder.encoders.1.self_attn.linear_out.bias to zeros\n",
      "Initialize decoder.encoders.1.feed_forward.w_1.bias to zeros\n",
      "Initialize decoder.encoders.1.feed_forward.w_2.bias to zeros\n",
      "Initialize decoder.encoders.1.norm1.bias to zeros\n",
      "Initialize decoder.encoders.1.norm2.bias to zeros\n",
      "Initialize decoder.encoders.2.self_attn.linear_q.bias to zeros\n",
      "Initialize decoder.encoders.2.self_attn.linear_k.bias to zeros\n",
      "Initialize decoder.encoders.2.self_attn.linear_v.bias to zeros\n",
      "Initialize decoder.encoders.2.self_attn.linear_out.bias to zeros\n",
      "Initialize decoder.encoders.2.feed_forward.w_1.bias to zeros\n",
      "Initialize decoder.encoders.2.feed_forward.w_2.bias to zeros\n",
      "Initialize decoder.encoders.2.norm1.bias to zeros\n",
      "Initialize decoder.encoders.2.norm2.bias to zeros\n",
      "Initialize decoder.encoders.3.self_attn.linear_q.bias to zeros\n",
      "Initialize decoder.encoders.3.self_attn.linear_k.bias to zeros\n",
      "Initialize decoder.encoders.3.self_attn.linear_v.bias to zeros\n",
      "Initialize decoder.encoders.3.self_attn.linear_out.bias to zeros\n",
      "Initialize decoder.encoders.3.feed_forward.w_1.bias to zeros\n",
      "Initialize decoder.encoders.3.feed_forward.w_2.bias to zeros\n",
      "Initialize decoder.encoders.3.norm1.bias to zeros\n",
      "Initialize decoder.encoders.3.norm2.bias to zeros\n",
      "Initialize decoder.after_norm.bias to zeros\n",
      "Initialize generator.input_conv.bias to zeros\n",
      "Initialize generator.upsamples.0.1.bias to zeros\n",
      "Initialize generator.upsamples.1.1.bias to zeros\n",
      "Initialize generator.upsamples.2.1.bias to zeros\n",
      "Initialize generator.upsamples.3.1.bias to zeros\n",
      "Initialize generator.blocks.0.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.0.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.0.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.0.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.0.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.0.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.1.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.1.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.1.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.1.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.1.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.1.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.2.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.2.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.2.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.2.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.2.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.2.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.3.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.3.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.3.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.3.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.3.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.3.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.4.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.4.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.4.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.4.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.4.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.4.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.5.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.5.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.5.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.5.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.5.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.5.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.6.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.6.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.6.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.6.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.6.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.6.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.7.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.7.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.7.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.7.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.7.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.7.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.8.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.8.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.8.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.8.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.8.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.8.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.9.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.9.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.9.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.9.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.9.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.9.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.10.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.10.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.10.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.10.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.10.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.10.convs2.2.1.bias to zeros\n",
      "Initialize generator.blocks.11.convs1.0.1.bias to zeros\n",
      "Initialize generator.blocks.11.convs1.1.1.bias to zeros\n",
      "Initialize generator.blocks.11.convs1.2.1.bias to zeros\n",
      "Initialize generator.blocks.11.convs2.0.1.bias to zeros\n",
      "Initialize generator.blocks.11.convs2.1.1.bias to zeros\n",
      "Initialize generator.blocks.11.convs2.2.1.bias to zeros\n",
      "Initialize generator.output_conv.1.bias to zeros\n",
      "It seems weight norm is not applied in the pretrained model but the current model uses it. To keep the compatibility, we remove the norm from the current model. This may cause unexpected behavior due to the parameter mismatch in finetuning. To avoid this issue, please change the following parameters in config to false:\n",
      " - discriminator_params.follow_official_norm\n",
      " - discriminator_params.scale_discriminator_params.use_weight_norm\n",
      " - discriminator_params.scale_discriminator_params.use_spectral_norm\n",
      "\n",
      "See also:\n",
      " - https://github.com/espnet/espnet/pull/5240\n",
      " - https://github.com/espnet/espnet/pull/5249\n",
      "Extractor:\n",
      "LogMelFbank(\n",
      "  (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)\n",
      "  (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=80, fmax=7600, htk=False)\n",
      ")\n",
      "Normalizer:\n",
      "GlobalMVN(stats_file=exp/tts_stats_raw_phn_tacotron_g2p_en_no_space/train/feats_stats.npz, norm_means=True, norm_vars=True)\n",
      "TTS:\n",
      "JETS(\n",
      "  (generator): JETSProsodyGenerator(\n",
      "    (encoder): Encoder(\n",
      "      (embed): Sequential(\n",
      "        (0): Embedding(78, 256, padding_idx=0)\n",
      "        (1): ScaledPositionalEncoding(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoders): MultiSequential(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (1): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (2): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (3): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (duration_predictor): DurationPredictor(\n",
      "      (conv): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (pitch_predictor): VariancePredictor(\n",
      "      (conv): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (pitch_embed): Sequential(\n",
      "      (0): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (energy_predictor): VariancePredictor(\n",
      "      (conv): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): ReLU()\n",
      "          (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (energy_embed): Sequential(\n",
      "      (0): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (alignment_module): AlignmentModule(\n",
      "      (t_conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (t_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (f_conv1): Conv1d(80, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (f_conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (f_conv3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (length_regulator): GaussianUpsampling()\n",
      "    (decoder): Encoder(\n",
      "      (embed): Sequential(\n",
      "        (0): ScaledPositionalEncoding(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoders): MultiSequential(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (1): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (2): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (3): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): MultiLayeredConv1d(\n",
      "            (w_1): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (w_2): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (generator): HiFiGANGenerator(\n",
      "      (input_conv): Conv1d(256, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (upsamples): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.1)\n",
      "          (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.1)\n",
      "          (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.1)\n",
      "          (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.1)\n",
      "          (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "        )\n",
      "      )\n",
      "      (blocks): ModuleList(\n",
      "        (0): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): ResidualBlock(\n",
      "          (convs1): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.1)\n",
      "              (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (output_conv): Sequential(\n",
      "        (0): LeakyReLU(negative_slope=0.01)\n",
      "        (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(\n",
      "    (msd): HiFiGANMultiScaleDiscriminator(\n",
      "      (discriminators): ModuleList(\n",
      "        (0): HiFiGANScaleDiscriminator(\n",
      "          (layers): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (3): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (4): Sequential(\n",
      "              (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (5): Sequential(\n",
      "              (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (6): Sequential(\n",
      "              (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mpd): HiFiGANMultiPeriodDiscriminator(\n",
      "      (discriminators): ModuleList(\n",
      "        (0): HiFiGANPeriodDiscriminator(\n",
      "          (convs): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (3): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (4): Sequential(\n",
      "              (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "          )\n",
      "          (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))\n",
      "        )\n",
      "        (1): HiFiGANPeriodDiscriminator(\n",
      "          (convs): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (3): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (4): Sequential(\n",
      "              (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "          )\n",
      "          (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))\n",
      "        )\n",
      "        (2): HiFiGANPeriodDiscriminator(\n",
      "          (convs): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (3): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (4): Sequential(\n",
      "              (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "          )\n",
      "          (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))\n",
      "        )\n",
      "        (3): HiFiGANPeriodDiscriminator(\n",
      "          (convs): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (3): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (4): Sequential(\n",
      "              (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "          )\n",
      "          (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))\n",
      "        )\n",
      "        (4): HiFiGANPeriodDiscriminator(\n",
      "          (convs): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (3): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "            (4): Sequential(\n",
      "              (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "              (1): LeakyReLU(negative_slope=0.1)\n",
      "            )\n",
      "          )\n",
      "          (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator_adv_loss): GeneratorAdversarialLoss()\n",
      "  (discriminator_adv_loss): DiscriminatorAdversarialLoss()\n",
      "  (feat_match_loss): FeatureMatchLoss()\n",
      "  (mel_loss): MelSpectrogramLoss(\n",
      "    (wav_to_mel): LogMelFbank(\n",
      "      (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)\n",
      "      (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)\n",
      "    )\n",
      "  )\n",
      "  (var_loss): VarianceLoss(\n",
      "    (mse_criterion): MSELoss()\n",
      "    (duration_criterion): DurationPredictorLoss(\n",
      "      (criterion): MSELoss()\n",
      "    )\n",
      "  )\n",
      "  (forwardsum_loss): ForwardSumLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "os.chdir(LJSPEECH_DIR)\n",
    "pretrained_dir = LJSPEECH_DIR / \"exp/tts_train_jets_raw_phn_tacotron_g2p_en_no_space\"\n",
    "pretrained_model_file = pretrained_dir / \"train.total_count.ave_5best.pth\"\n",
    "pretrained_tts = Text2Speech.from_pretrained(\n",
    "    train_config=pretrained_dir / \"config_prosody.yaml\",\n",
    "    model_file=pretrained_model_file,\n",
    "    device=device\n",
    ")\n",
    "pretrained_model = pretrained_tts.model\n",
    "os.chdir(PWD)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "arpa_tokenizer = PhonemeTokenizer(g2p_type='g2p_en_no_space')\n",
    "id_converter = TokenIDConverter(pretrained_tts.train_args.token_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "save_dir = PWD / 'outputs/tts_train_jets_raw_phn_tacotron_g2p_en_no_space/aishell3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "pas = PinyinArpaSpeech(token_id_converter=id_converter, tts_inference_fn=pretrained_model.tts.generator.inference)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try on the first line of the AISHELL-3 dataset.\n",
    "line = 'SSB06930002.wav\t武 wu3 术 shu4 始 shi3 终 zhong1 被 bei4 看 kan4 作 zuo4 我 wo3 国 guo2 的 de5 国 guo2 粹 cui4'\n",
    "custom_filename, chinese = line.strip().split(maxsplit=1)\n",
    "chinese = re.sub(r'[ a-z0-9]', '', chinese) + '。'\n",
    "\n",
    "inputs = pas.gen_audio(\n",
    "    chinese,\n",
    "    save_dir,\n",
    "    verbose=True,\n",
    "    overall_d_factor=8.0,\n",
    "    fix_durations=True,\n",
    "    arpa_in_filename=False,\n",
    "    custom_filename=custom_filename,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Now run on entire dataset\n",
    "transcript_file = (PWD / '../../datasets/data_aishell3/test/content.txt').resolve()\n",
    "with open(transcript_file) as f:\n",
    "    for line in f:\n",
    "        custom_filename, chinese = line.strip().split(maxsplit=1)\n",
    "        chinese = re.sub(r'[ a-z0-9]', '', chinese) + '。'\n",
    "\n",
    "\n",
    "        pas_update_dict = {\n",
    "            'pinyin_to_arpa_durations': {},\n",
    "            'tone_duration_split': {},\n",
    "            'tone_contours': {},\n",
    "            'nucleus_tone_only': False,\n",
    "            'max_pitch_change': 2.5,\n",
    "        }\n",
    "        infer_overrides = {\n",
    "            'd_split_factor': None,\n",
    "            'd_factor': None,\n",
    "            'p_factor': None,\n",
    "            'e_factor': None,\n",
    "            'd_mod_fns': None,\n",
    "            'p_mod_fns': None,\n",
    "            'e_mod_fns': None,\n",
    "        }\n",
    "        inputs = pas.gen_audio(\n",
    "            chinese,\n",
    "            save_dir,\n",
    "            verbose=True,\n",
    "            # disable_tones=True,\n",
    "            inputs=None,\n",
    "            pac_update_dict=pas_update_dict,\n",
    "            infer_overrides=infer_overrides,\n",
    "            overall_d_factor=8.0,\n",
    "            fix_durations=True,\n",
    "            arpa_in_filename=False,\n",
    "            custom_filename=custom_filename,\n",
    "            device=device,\n",
    "        )\n",
    "        # arpas, tones, d_factor, d_split_factor, pitch_values, p_mod_fns = inputs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try again without tones\n",
    "save_dir = PWD / 'outputs/tts_train_jets_raw_phn_tacotron_g2p_en_no_space/aishell3_nopitch'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(transcript_file) as f:\n",
    "    for line in f:\n",
    "        custom_filename, chinese = line.strip().split(maxsplit=1)\n",
    "        chinese = re.sub(r'[ a-z0-9]', '', chinese) + '。'\n",
    "\n",
    "        inputs = pas.gen_audio(\n",
    "            chinese,\n",
    "            save_dir,\n",
    "            verbose=True,\n",
    "            disable_tones=True,\n",
    "            inputs=None,\n",
    "            pac_update_dict=pas_update_dict,\n",
    "            infer_overrides=infer_overrides,\n",
    "            overall_d_factor=8.0,\n",
    "            fix_durations=True,\n",
    "            arpa_in_filename=False,\n",
    "            custom_filename=custom_filename,\n",
    "            device=device,\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
