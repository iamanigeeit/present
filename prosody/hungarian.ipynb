{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:39.091239Z",
     "start_time": "2024-07-21T01:48:35.388931Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from pathlib import Path\n",
    "from espnet2.text.phoneme_tokenizer import PhonemeTokenizer\n",
    "from espnet2.text.token_id_converter import TokenIDConverter\n",
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "PWD = %pwd\n",
    "PWD = Path(PWD)\n",
    "LJSPEECH_DIR = (PWD / '../egs2/ljspeech/tts1/').resolve()\n",
    "DATA_DIR = (PWD / '../../datasets/CSS10/hungarian/').resolve()\n",
    "device = 'cuda'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:40.922795Z",
     "start_time": "2024-07-21T01:48:39.092355Z"
    }
   },
   "source": [
    "os.chdir(LJSPEECH_DIR)\n",
    "pretrained_dir = LJSPEECH_DIR / \"exp/tts_train_jets_raw_phn_tacotron_g2p_en_no_space\"\n",
    "pretrained_model_file = pretrained_dir / \"train.total_count.ave_5best.pth\"\n",
    "pretrained_tts = Text2Speech.from_pretrained(\n",
    "    train_config=pretrained_dir / \"config_prosody.yaml\",\n",
    "    model_file=pretrained_model_file,\n",
    "    device=device\n",
    ")\n",
    "pretrained_model = pretrained_tts.model\n",
    "os.chdir(PWD)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/perry/miniconda3/envs/espnet/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems weight norm is not applied in the pretrained model but the current model uses it. To keep the compatibility, we remove the norm from the current model. This may cause unexpected behavior due to the parameter mismatch in finetuning. To avoid this issue, please change the following parameters in config to false:\n",
      " - discriminator_params.follow_official_norm\n",
      " - discriminator_params.scale_discriminator_params.use_weight_norm\n",
      " - discriminator_params.scale_discriminator_params.use_spectral_norm\n",
      "\n",
      "See also:\n",
      " - https://github.com/espnet/espnet/pull/5240\n",
      " - https://github.com/espnet/espnet/pull/5249\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:40.951852Z",
     "start_time": "2024-07-21T01:48:40.923859Z"
    }
   },
   "source": [
    "arpa_tokenizer = PhonemeTokenizer(g2p_type='g2p_en_no_space')\n",
    "id_converter = TokenIDConverter(pretrained_tts.train_args.token_list)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T21:12:39.782684Z",
     "start_time": "2024-07-19T21:12:39.739266Z"
    }
   },
   "cell_type": "code",
   "source": "from en_to_hu import phonemize, G2P",
   "outputs": [],
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:41.460009Z",
     "start_time": "2024-07-21T01:48:40.952912Z"
    }
   },
   "source": [
    "from phonemizer.backend import BACKENDS\n",
    "from phonemizer.separator import Separator\n",
    "G2P = BACKENDS['espeak'](\n",
    "    language='hu',\n",
    "    preserve_punctuation=True,\n",
    "    with_stress=True,\n",
    ")\n",
    "SEP = Separator(word='|', phone=' ')\n",
    "def phonemize_base(text):\n",
    "    phonestr = G2P.phonemize([text], separator=SEP)[0]\n",
    "    phones = phonestr.replace('|', ' | ').strip().split()\n",
    "    return phones"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T09:36:43.332978Z",
     "start_time": "2024-07-18T09:36:43.271080Z"
    }
   },
   "cell_type": "code",
   "source": "G2P.phonemize(['De azért akik megszokták, értették a beszédét.', 'Folytatta: - és kedves Juliska!'], separator=SEP)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:phonemizer:words count mismatch on 50.0% of the lines (1/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d ˌɛ | ˈɑ z eː r t | ˈɑ k i k |m ˈɛ ɡ s o k t aː k |,  ˈeː r t ɛ tː eː k | ˌɑ |b ˈɛ s eː d eː t |.', 'f ˈo j t ɑ tː ɑ |:  ˌeː ʃ |k ˈɛ d v ɛ ʃ |j ˈu l i ʃ k ɑ |!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['d ˌɛ | ˈɑ z eː r t | ˈɑ k i k |m ˈɛ ɡ s o k t aː k |,  ˈeː r t ɛ tː eː k | ˌɑ |b ˈɛ s eː d eː t |.',\n",
       " 'f ˈo j t ɑ tː ɑ |:  ˌeː ʃ |k ˈɛ d v ɛ ʃ |j ˈu l i ʃ k ɑ |!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "phoneset = set()\n",
    "# Please correct invalid characters\n",
    "with open(DATA_DIR / 'transcript_phones_espeak.txt', 'w') as phones_f:\n",
    "    with open(DATA_DIR / 'transcript.txt') as f:\n",
    "        for line in f:\n",
    "            filename, _, text2, _ = line.split('|')\n",
    "            if not text2:\n",
    "                continue\n",
    "            # G2P.logger.warning(f'{filename}')\n",
    "            # phones = phonemize(text2)\n",
    "            phones = phonemize(text2)\n",
    "            phones_f.write(f'{filename}|{\" \".join(phones)}\\n')\n",
    "            phoneset |= set(phones)\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T10:09:51.444988Z",
     "start_time": "2024-07-18T10:09:51.334432Z"
    }
   },
   "source": [
    "# from en_to_hu import PHONES_MAP, PUNCS\n",
    "# phoneset = set(PHONES_MAP.keys()) | set(PUNCS)\n",
    "phoneset = set()\n",
    "with open(DATA_DIR / 'transcript_phones_espeak.txt') as f:\n",
    "    for line in f:\n",
    "        filename, trans = line.split('|', maxsplit=1)\n",
    "        for phone in trans.strip().split():\n",
    "            if phone not in phoneset:\n",
    "                phoneset.add(phone)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T21:13:13.889252Z",
     "start_time": "2024-07-19T21:13:13.843443Z"
    }
   },
   "cell_type": "code",
   "source": "' '.join(sorted(phoneset))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'! , . ? aː b bː c cː d dzː dʒ dː eː f h i iː j k kː l m n o oː p pː r s t ts tsː tʃ tʃː tː u uː v y yː z | ø øː ɑ ɛ ɟ ɟː ɡ ɡː ɲ ʃ ʎ ʒ ˈaː ˈeː ˈi ˈiː ˈo ˈoː ˈu ˈuː ˈy ˈyː ˈø ˈøː ˈɑ ˈɑː ˈɛ ˌaː ˌeː ˌi ˌiː ˌo ˌoː ˌu ˌuː ˌy ˌyː ˌø ˌøː ˌɑ ˌɛ'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:46:50.746734Z",
     "start_time": "2024-07-18T14:46:50.686881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from en_to_hu import VOWELS_MAP, CONSONANTS_MAP\n",
    "print(' '.join(x for x in VOWELS_MAP.keys() if 'ˈ' not in x and 'ˌ' not in x))\n",
    "print(' '.join(CONSONANTS_MAP.keys()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aː ɑ eː ɛ i iː o oː ø øː u uː y yː\n",
      "b bː c cː d dː dzː dʒ f h j k kː l m n p pː r s t tː ts tsː tʃ tʃː v z ɟ ɟː ɡ ɡː ɲ ʃ ʎ ʒ\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:46.702404Z",
     "start_time": "2024-07-21T01:48:46.201855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "phone_freq_csv = DATA_DIR / 'phone_freq.csv'\n",
    "phones = 'aː ɑ ɑː eː ɛ i iː o oː ø øː u uː y yː b bː c cː d dː dzː dʒ f h j k kː l m n p pː r s t tː ts tsː tʃ tʃː v z ɟ ɟː ɡ ɡː ɲ ʃ ʎ ʒ'.split()\n",
    "if phone_freq_csv.exists():\n",
    "    df = pd.read_csv(phone_freq_csv, index_col='filename')\n",
    "else:\n",
    "    filenames = []\n",
    "    transcripts = []\n",
    "    with open(DATA_DIR / 'transcript_phones_espeak.txt') as f:\n",
    "        for line in f:\n",
    "            filename, trans = line.split('|', maxsplit=1)\n",
    "            trans = trans.strip() + ' '\n",
    "            filenames.append(filename)\n",
    "            transcripts.append(trans)\n",
    "    df = pd.DataFrame({'filename': filenames, 'transcript': transcripts})\n",
    "    df.set_index('filename', inplace=True)\n",
    "    for phone in phones:\n",
    "        df[phone] = df.transcript.str.count(phone + ' ')\n",
    "    df.to_csv(phone_freq_csv)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:46.973992Z",
     "start_time": "2024-07-21T01:48:46.922169Z"
    }
   },
   "source": [
    "def get_top_transcripts(phone, top_n=2):\n",
    "    return df.sort_values(by=phone, ascending=False).head(top_n)['transcript'].to_dict()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:49.407119Z",
     "start_time": "2024-07-21T01:48:48.178613Z"
    }
   },
   "source": [
    "from en_to_hu import HungarianArpaSpeech, phonemize\n",
    "has = HungarianArpaSpeech(token_id_converter=id_converter, tts_inference_fn=pretrained_model.tts.generator.inference)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:49.441475Z",
     "start_time": "2024-07-21T01:48:49.408199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# phones_map = {'a': 'AH2',\n",
    "#     'ˌa': ('AH1', '1', '1'),\n",
    "#     'ˈa': ('AH1', '1', '2'),}\n",
    "def gen_phones_audio(phone, top_n=2, print_phones=True):\n",
    "    top_trans = get_top_transcripts(phone, top_n)\n",
    "    if print_phones:\n",
    "        print(phone)\n",
    "        print(top_trans)\n",
    "    for fname, phones_str in top_trans.items():\n",
    "        hungarian = phones_str.strip().split()\n",
    "        inputs = has.gen_audio(\n",
    "            hungarian,\n",
    "            save_dir=PWD / f'outputs/tts_train_jets_raw_phn_tacotron_g2p_en_no_space/hungarian/{phone}',\n",
    "            verbose=False,\n",
    "            # phones_map=phones_map,\n",
    "            # verbose=True,\n",
    "            custom_filename=fname.split('/')[1],\n",
    "            device=device,\n",
    "        )\n",
    "    return inputs"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T15:57:51.250512Z",
     "start_time": "2024-07-20T15:57:51.207772Z"
    }
   },
   "cell_type": "code",
   "source": "inputs = has.gen_inputs('ˈɛ ɟ | ˈy ɟ ɛ ʃ | l ˈɛ ɡ eː ɲ | h ˈɑ n dʒ aː r t |'.split(), verbose=True)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -1      0    1    2    3    4    5    6    7    8    9    10    11    12    13    14    15    16    17    18    19    20    21    22    23    24\n",
      " arpas    EH1   G   HH    ,   UH1   Y    G    Y   EH0  SH    L    EH1    G    EY0    N     Y     ,     HH   AA1    N     D     ZH   AH2    R     T\n",
      "d_factor   1   0.4  0.4   0    0    1   0.7   0    1    1    1     1    0.7    1    0.8   0.2    0     1    0.5    1    0.7   0.3    1     1    0.7\n",
      "p_factor   0    0    0    0    0    0    0    0    0    0    0     0     0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "e_factor   0    0    0    0    0    0    0    0    0    0    0     0     0     0     0     0     0     0     0     0     0     0     0     0     0\n"
     ]
    }
   ],
   "execution_count": 341
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T08:45:23.194883Z",
     "start_time": "2024-07-20T08:45:22.998798Z"
    }
   },
   "cell_type": "code",
   "source": "inputs = has.gen_audio('. hej help mi', save_dir=PWD / f'outputs/tts_train_jets_raw_phn_tacotron_g2p_en_no_space/hungarian/')",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:48:53.913908Z",
     "start_time": "2024-07-21T01:48:52.670715Z"
    }
   },
   "cell_type": "code",
   "source": "inputs = gen_phones_audio(phone='u', top_n=3)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n",
      "{'egri_csillagok/egri_csillagok_2932.wav': 'k ˈɑ r ɟ u k | d ˈɑ m ɑ s k u s b ɑ n | k ˌeː s y l t | , v ˈeː r c y k | d ˈɛ r b ɛ n d i | ˈɑ ts eː l | , l ˈaː n dʒ aː j u k | h ˈi n d o s t aː n i | m ˈɛ ʃ t ɛ r k o v aː tʃ o k t oː l | v ˌɑ l oː | , ˈaː ɟ uː i k ɑ t | ˈɛ u r oː p ɑ | l ˈɛ ɡ j o bː | ˈø n t øː i | ˈɑ l k o cː aː k | m ˌɛ ɡ | , p ˈu ʃ k ɑ p o r u k | , ɡ ˈo j oː j u k | , f ˈɛ ɟ v ɛ r y k | m ˈeː r h ɛ t ɛ t l ɛ n | ˌeː ʃ | m ˈɛ ɡ s aː m l aː l h ɑ t ɑ t l ɑ n | . ', 'egri_csillagok/egri_csillagok_4228.wav': 'ˌɑ | s ˈɛ n tʃ eː ɡ b ɛ n | , ˈɑ m i t | ˈi tː | l ˈaː t u n k | , t ˈu ɟː u k | , h ˌo ɟ ˌɑ z | ˈeː l øː | j ˈeː z u ʃ | v ˈɑ n | j ˈɛ l ɛ n | . v ˈɛ l y n k | v ˌɑ n | ! b ˈo r u ʎ j u n k | l ˌɛ | , ˌeː ʃ | ˈi m aː d k o z z u n k | ! ', 'egri_csillagok/egri_csillagok_2315.wav': 't ˈu d o d | , ˈu r ɑ m | , s ˈɛ ɡ eː ɲ ɛ k | v ˌɑ ɟ u n k | , h ˈaː t | ˈɛ ʃ t eː n k i n t | h ˈɑ l aː s n u n k | k ˌɛ l l | . h ˈɑ n ɛ m | ˌɑ z | ˈeː ʎ j ɛ l | n ˈɛ m tʃ ɑ k | h ˈɑ l ɑ t | f ˈo ɡ t u n k | . ˈɑ h o ɟ | k ˈi h uː z z u k | ˌɑ | h ˈaː l oː t | , v ˈɑ l ɑ m i | m ˈɛ ɡ tʃ i l l ɑ n i k | b ˌɛ n n ɛ | . '}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T21:16:03.847145Z",
     "start_time": "2024-07-19T21:14:36.122088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for phone in phones:\n",
    "    _ = gen_phones_audio(phone, top_n=3, print_phones=False)"
   ],
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T09:50:34.280553Z",
     "start_time": "2024-07-01T09:50:34.099279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hungarian = 'creíais oíais'\n",
    "custom_filename = hungarian + '.wav' if isinstance(hungarian, str) else ''.join(hungarian) + '.wav'\n",
    "arpas, d_factor, p_factor, e_factor = has.gen_inputs(hungarian)\n",
    "# d_factor[0, 1] *= 1.5\n",
    "custom_arpa_subs = {}\n",
    "# for i in range(3):\n",
    "#     custom_arpa_subs[f'N UW{i}'] = (f'N N UW{i}', '0 0.7 0', '0 =0 =1', '0 =0 =1')\n",
    "#     custom_arpa_subs[f'T UW{i}'] = (f'T W W', '=0 1 =1', '=0 0 =1', '=0 0 =1')\n",
    "inputs = has.gen_audio(\n",
    "    hungarian,\n",
    "    # inputs=(arpas, d_factor, p_factor, e_factor),\n",
    "    save_dir=PWD / f'outputs/tts_train_jets_raw_phn_tacotron_g2p_en_no_space/hungarian',\n",
    "    # verbose=False,\n",
    "    custom_arpa_subs=custom_arpa_subs,\n",
    "    verbose=True,\n",
    "    custom_filename=custom_filename,\n",
    "    device=device,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated \n",
      "   -1      0    1    2    3    4    5    6    7    8    9    10    11    12    13    14    15    16\n",
      " arpas     K    R   EH0   Y   IY1   Y   AA0   Y    S    ,   OW0    Y    IY1    Y    AA0    Y     S\n",
      "d_factor  0.7   1    1   0.4  0.7  0.4   1   0.4   1    0    1    0.4   0.7   0.4    1    0.4    1\n",
      "p_factor   0    0    0    0    1    0    0    0    0    0    0     0     1     0     0     0     0\n",
      "e_factor   0    0   0.5   0   0.5   0   0.5   0    0    0   0.5    0    0.5    0    0.5    0     0\n",
      "Duration pred: tensor([ 5.9971,  6.2804,  8.7144,  7.8999,  9.0675,  8.4928,  9.2692, 10.6716,\n",
      "        10.3342, 20.5245, 12.5303,  9.2557,  8.4650,  9.1517,  9.3981, 11.4364,\n",
      "        19.4551], device='cuda:0')\n",
      "Pitch pred: tensor([ 0.9911,  1.0531,  0.6471,  0.3290,  0.2310, -0.4055, -0.8396, -0.4751,\n",
      "        -0.2946, -0.6380, -0.4088,  0.2300,  0.6042, -0.2134, -0.9145, -0.6451,\n",
      "        -0.4752], device='cuda:0')\n",
      "Energy pred: tensor([-0.8592,  1.2776,  0.6716,  0.2274,  0.3890,  0.3921,  0.1916, -0.2506,\n",
      "         0.0990, -0.7427,  0.2675,  0.0872,  0.3634,  0.3517,  0.0853, -0.1341,\n",
      "        -0.0624], device='cuda:0')\n",
      "Duration (new): tensor([ 4,  6,  9,  3,  6,  3,  9,  4, 10,  0, 13,  4,  6,  4,  9,  5, 19],\n",
      "       device='cuda:0')\n",
      "Pitch (new): tensor([ 0.9911,  1.0531,  0.6471,  0.3290,  1.2310, -0.4055, -0.8396, -0.4751,\n",
      "        -0.2946, -0.6380, -0.4088,  0.2300,  1.6042, -0.2134, -0.9145, -0.6451,\n",
      "        -0.4752], device='cuda:0')\n",
      "Energy (new): tensor([-0.8592,  1.2776,  1.1716,  0.2274,  0.8890,  0.3921,  0.6916, -0.2506,\n",
      "         0.0990, -0.7427,  0.7675,  0.0872,  0.8634,  0.3517,  0.5853, -0.1341,\n",
      "        -0.0624], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-20T18:44:51.411636Z",
     "start_time": "2024-07-20T18:25:42.292975Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "# Now run on entire dataset\n",
    "save_dir = PWD / 'outputs/tts_train_jets_raw_phn_tacotron_g2p_en_no_space/CSS10/hungarian'\n",
    "transcript_file = (DATA_DIR / 'transcript_phones_espeak.txt').resolve()\n",
    "with open(transcript_file) as f:\n",
    "    for line in tqdm(f.read().splitlines()):\n",
    "        custom_filename, phones = line.strip().split('|', maxsplit=1)\n",
    "        if (save_dir / custom_filename).exists():\n",
    "            continue\n",
    "        hungarian = phones.split()\n",
    "        \n",
    "        inputs = has.gen_audio(\n",
    "            hungarian,\n",
    "            save_dir=save_dir,\n",
    "            verbose=False,\n",
    "            custom_filename=custom_filename,\n",
    "            # verbose=True,\n",
    "            device=device,\n",
    "        )\n",
    "        # arpas, d_factor, e_factor = inputs\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4514/4514 [19:09<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
