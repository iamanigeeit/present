{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately Paraformer packages are not compatible with ESPnet. Create a new env and pip install\n",
    "```\n",
    "conda install -n funasr python=3.10  # installing jiwer fails on 3.11 (levenshtein dependency)\n",
    "pip install jiwer==2.5  # 2.6 onwards conflicts with funasr's g2p click dependency\n",
    "pip install funasr-onnx\n",
    "```\n",
    "before running this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from funasr_onnx import Paraformer\n",
    "import jiwer\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "PWD = %pwd\n",
    "PWD = Path(PWD)\n",
    "outputs_dir = PWD / 'outputs'\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "jets_dir = outputs_dir / 'tts_train_jets_raw_phn_tacotron_g2p_en_no_space/aishell3'\n",
    "nopitch_dir = outputs_dir / 'tts_train_jets_raw_phn_tacotron_g2p_en_no_space/aishell3_nopitch'\n",
    "model_dir = (PWD / \"../../paraformer-large/\").resolve()\n",
    "data_dir = Path('../../datasets/data_aishell3/').resolve()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Paraformer(model_dir, device_id=-1, batch_size=1, quantize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try running ASR on the first transcript\n",
    "model([jets_dir / 'SSB06930002.wav'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_asr(wav_paths, asr_result_path):\n",
    "    with open(asr_result_path, 'w') as f:\n",
    "        for wav_path in wav_paths:\n",
    "            result = model([wav_path])[0]\n",
    "            wordlist = result['preds'][1]\n",
    "            f.write(f'{wav_path.parts[-1]} {wordlist}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gt_dir = data_dir / 'test/wav'\n",
    "gt_paths = sorted(gt_dir.glob('*/*.wav'))\n",
    "gt_asr_path = model_dir / 'gt_result.txt'\n",
    "run_asr(gt_paths, gt_asr_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets_paths = sorted(jets_dir.glob('*.wav'))\n",
    "jets_asr_path = model_dir / 'jets_result.txt'\n",
    "run_asr(jets_paths, jets_asr_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nopitch_paths = sorted(nopitch_dir.glob('*.wav'))\n",
    "nopitch_asr_path = model_dir / 'nopitch_result.txt'\n",
    "run_asr(nopitch_paths, nopitch_asr_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transcript_file = data_dir / 'test/content.txt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_transcripts():\n",
    "    transcripts = {}\n",
    "    with open(transcript_file) as f:\n",
    "        for line in f:\n",
    "            wav_file, transcript = line.strip().split(maxsplit=1)\n",
    "            transcripts[wav_file] = re.sub(r'[ a-z0-9]', '', transcript)\n",
    "    return transcripts\n",
    "\n",
    "transcripts = get_transcripts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_wer(transcripts, asr_result_path, wer_path):\n",
    "    with open(wer_path, 'w') as wer_file:\n",
    "        wer_file.write('wav_file,gt_len,wer,eng_words\\n')\n",
    "        with open(asr_result_path) as f:\n",
    "            for line in f:\n",
    "                wav_file, asr_output = line.strip().split(maxsplit=1)\n",
    "                asr_output = literal_eval(asr_output)\n",
    "                eng_words = sum([word.isascii() for word in asr_output])\n",
    "                transcript = transcripts[wav_file]\n",
    "                gt_len = len(transcript)\n",
    "                wer = jiwer.wer(truth=' '.join(transcript), hypothesis=' '.join(asr_output))\n",
    "                wer_file.write(f'{wav_file},{gt_len},{wer},{eng_words}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets_wer_path = outputs_dir / 'jets_wer.csv'\n",
    "eval_wer(transcripts=transcripts, asr_result_path=jets_asr_path, wer_path=jets_wer_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "nopitch_wer_path = outputs_dir / 'nopitch_wer.csv'\n",
    "eval_wer(transcripts=transcripts, asr_result_path=nopitch_asr_path, wer_path=nopitch_wer_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def eval_cer(transcripts, asr_result_path, cer_path):\n",
    "    from prosody.en_to_zh import hans_to_pinyin\n",
    "    with open(cer_path, 'w') as cer_file:\n",
    "        cer_file.write('wav_file,gt_len,cer,eng_words\\n')\n",
    "        with open(asr_result_path) as f:\n",
    "            for line in f:\n",
    "                wav_file, asr_output = line.strip().split(maxsplit=1)\n",
    "                asr_output = literal_eval(asr_output)\n",
    "                eng_words = sum([word.isascii() for word in asr_output])\n",
    "                transcript = transcripts[wav_file]\n",
    "                trans_pinyin = ''.join(hans_to_pinyin(transcript))\n",
    "                gt_len = len(trans_pinyin)\n",
    "                asr_pinyin = ''.join(hans_to_pinyin(asr_output)).lower()\n",
    "                cer = jiwer.cer(truth=trans_pinyin, hypothesis=asr_pinyin)\n",
    "                cer_file.write(f'{wav_file},{gt_len},{cer},{eng_words}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "jets_asr_path = model_dir / 'jets_result.txt'\n",
    "jets_cer_path = outputs_dir / 'jets_cer.csv'\n",
    "eval_cer(transcripts=transcripts, asr_result_path=jets_asr_path, cer_path=jets_cer_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
