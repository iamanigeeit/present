{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately Paraformer packages are not compatible with ESPnet. Run\n",
    "```\n",
    "conda create -n funasr python=3.10  # installing jiwer fails on 3.11 (levenshtein dependency)\n",
    "conda activate funasr\n",
    "pip install jiwer==2.5  # 2.6 onwards conflicts with funasr's g2p click dependency\n",
    "pip install -U modelscope==1.10 funasr==0.8.7 pywordseg torchaudio transformers==4.39.2 charset-normalizer tabulate overrides==4.1.2\n",
    "```\n",
    "before running this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import faster_whisper\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "import regex as re\n",
    "\n",
    "PWD = %pwd\n",
    "PWD = Path(PWD)\n",
    "prosody_dir = PWD.parent\n",
    "outputs_dir = PWD / 'outputs' / 'aishell3'\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "prosody_outdir = prosody_dir / 'outputs'\n",
    "jets_dir = prosody_outdir / 'tts_train_jets_raw_phn_tacotron_g2p_en_no_space/aishell3'\n",
    "nopitch_dir = prosody_outdir / 'tts_train_jets_raw_phn_tacotron_g2p_en_no_space/aishell3_nopitch'\n",
    "baseline_dir = prosody_outdir / 'zm-text-tts/aishell3'\n",
    "data_dir = (prosody_dir / '../../datasets/data_aishell3/').resolve()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T08:20:18.482783Z",
     "start_time": "2024-07-15T08:20:17.247115Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:08:55.427878Z",
     "start_time": "2024-07-15T08:08:55.101014Z"
    }
   },
   "cell_type": "code",
   "source": "from prosody.pinyin import hans_to_pinyins",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "ld_lib_path = os.environ['LD_LIBRARY_PATH']\n",
    "assert 'cublas' in ld_lib_path and 'cudnn' in ld_lib_path\n",
    "model = faster_whisper.WhisperModel(\"large-v2\", device='cuda', compute_type='float16')\n",
    "asr_dir = outputs_dir / 'large-v2'\n",
    "os.makedirs(asr_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T08:20:26.233364Z",
     "start_time": "2024-07-15T08:20:20.386349Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:20:32.667209Z",
     "start_time": "2024-07-15T08:20:32.664786Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = model.hf_tokenizer",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:27:00.159057Z",
     "start_time": "2024-07-15T08:26:59.829012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Suppress numbers and letters from output\n",
    "tokenizer = model.hf_tokenizer\n",
    "suppress_tokens = [-1]\n",
    "alpha = set('qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM')\n",
    "for i in range(tokenizer.get_vocab_size()):\n",
    "    token = tokenizer.decode([i]).removeprefix(\" \")\n",
    "    # if re.search(r'\\P{Han}', token):\n",
    "    if re.search(r'[0-9]', token):\n",
    "        suppress_tokens.append(i)\n",
    "    if token in alpha:\n",
    "        suppress_tokens.append(i)\n",
    "\n",
    "whisper_kwargs = {\n",
    "    'suppress_tokens': suppress_tokens,\n",
    "    # 'temperature': 0.0,\n",
    "    'condition_on_previous_text': False,\n",
    "    'prepend_punctuations': '',\n",
    "    'append_punctuations': '',\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:26:33.989688Z",
     "start_time": "2024-07-15T08:26:33.986263Z"
    }
   },
   "cell_type": "code",
   "source": "len(suppress_tokens)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T05:48:36.703868Z",
     "start_time": "2024-07-15T05:48:36.695952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import opencc\n",
    "t2s = opencc.OpenCC('t2s.json')\n",
    "def normalize_chinese(hans):\n",
    "    hans = re.sub(r'\\P{Han}', '', hans)\n",
    "    hans = t2s.convert(hans)\n",
    "    return hans"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T05:54:05.545547Z",
     "start_time": "2024-07-15T05:54:05.542074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "line = '''SSB06930002.wav|武術始終被看作我國的國粹\n",
    "'''\n",
    "wav_file, asr_hans = line.strip('\\n').split('|', maxsplit=1)\n",
    "asr_hans = normalize_chinese(asr_hans)\n",
    "asr_pinyins = hans_to_pinyins(asr_hans)\n",
    "hans, pinyins = transcripts[wav_file]\n",
    "hanzi_len = len(hans)\n",
    "pinyin_len = len(pinyins)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T05:55:19.825072Z",
     "start_time": "2024-07-15T05:55:19.820692Z"
    }
   },
   "cell_type": "code",
   "source": "jiwer.cer(truth=hans, hypothesis=asr_hans)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:27:08.679671Z",
     "start_time": "2024-07-15T08:27:08.677046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def whisper_transcribe(filepath, kwargs=whisper_kwargs):\n",
    "    segments, _ = model.transcribe(filepath, language='zh', **kwargs)\n",
    "    text = ''.join(segment.text for segment in segments)\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": "whisper_transcribe(jets_dir / 'SSB18720176.wav')",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T08:27:14.522855Z",
     "start_time": "2024-07-15T08:27:09.926166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我們下次節目再見'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:50:46.337297Z",
     "start_time": "2024-07-13T08:50:46.332369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_asr(filenames, audio_dir, asr_result_path, is_two_level=False):\n",
    "    with open(asr_result_path, 'w') as f:\n",
    "        for filename in tqdm(filenames):\n",
    "            if is_two_level:\n",
    "                wav_path = audio_dir / filename[:7] / filename\n",
    "            else:\n",
    "                wav_path = audio_dir / filename\n",
    "            text = whisper_transcribe(wav_path)\n",
    "            f.write(f'{filename}|{text}\\n')"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T05:52:57.818816Z",
     "start_time": "2024-07-15T05:52:57.722042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transcript_file = data_dir / 'test/content_pinyin.txt'\n",
    "def get_transcripts():\n",
    "    transcripts = {}\n",
    "    with open(transcript_file) as f:\n",
    "        for line in f:\n",
    "            wav_file, transcript = line.strip().split('\\t', maxsplit=1)\n",
    "            hans, pinyin_str = transcript.split('|', maxsplit=1)\n",
    "            pinyin_str = ''.join(pinyin_str.split())\n",
    "            transcripts[wav_file] = (hans, pinyin_str)\n",
    "    return transcripts\n",
    "\n",
    "transcripts = get_transcripts()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T05:35:40.832288Z",
     "start_time": "2024-07-15T05:35:40.829310Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "gt_dir = data_dir / 'test/wav'\n",
    "gt_asr_path = asr_dir / 'gt_result.txt'\n",
    "\n",
    "jets_asr_path = asr_dir / 'jets_result.txt'\n",
    "\n",
    "nopitch_asr_path = asr_dir / 'nopitch_result.txt'\n",
    "\n",
    "baseline_asr_path = asr_dir / 'baseline_result.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T05:56:45.298149Z",
     "start_time": "2024-07-15T05:56:45.294710Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": "run_asr(transcripts.keys(), gt_dir, gt_asr_path, is_two_level=True)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T11:49:37.475838Z",
     "start_time": "2024-07-13T08:50:49.982151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24773/24773 [2:58:47<00:00,  2.31it/s]  \n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "run_asr(transcripts.keys(), jets_dir, jets_asr_path)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T15:11:43.000508Z",
     "start_time": "2024-07-13T11:49:37.479470Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24773/24773 [3:22:05<00:00,  2.04it/s]  \n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "run_asr(transcripts.keys(), nopitch_dir, nopitch_asr_path)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T18:43:13.383065Z",
     "start_time": "2024-07-13T15:11:43.001789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24773/24773 [3:31:30<00:00,  1.95it/s]   \n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T08:54:46.495244Z",
     "start_time": "2024-07-14T02:01:58.732662Z"
    }
   },
   "cell_type": "code",
   "source": "run_asr(transcripts.keys(), baseline_dir, baseline_asr_path)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24773/24773 [6:52:47<00:00,  1.00it/s]   \n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "nodur_dir = Path(str(nopitch_dir) + '_nodur')\n",
    "nodur_asr_path = asr_dir / 'nopitch_nodur_result.txt'\n",
    "run_asr(transcripts.keys(), nodur_dir, nodur_asr_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T19:17:39.460361Z",
     "start_time": "2024-07-14T12:15:37.981974Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24773/24773 [7:02:01<00:00,  1.02s/it]   \n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "def check_nonhans(asr_result_path):\n",
    "    non_hans = set()\n",
    "    with open(asr_result_path) as f:\n",
    "        for line in f:\n",
    "            asr_output = line.strip('\\n').split('|', maxsplit=1)[1]\n",
    "            asr_output = re.sub(r'\\p{Han}', '', asr_output)\n",
    "            non_hans |= set(asr_output)\n",
    "    return non_hans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T05:08:56.726927Z",
     "start_time": "2024-07-15T05:08:56.721610Z"
    }
   },
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": "print(''.join(sorted(check_nonhans(gt_asr_path))))",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T05:18:05.199721Z",
     "start_time": "2024-07-15T05:18:05.029474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"$%',-.:?BCDEFGHIJKLMNOPQRSTUVWXYabcdeghiklmnoprstuwy~¥·—…、。《》「」【】�\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T05:30:32.636751Z",
     "start_time": "2024-07-15T05:29:23.333265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "def write_nonhans(asr_result_path):\n",
    "    filenames, asr_outputs = [], []\n",
    "    with open(asr_result_path) as f:\n",
    "        for line in f:\n",
    "            filename, asr_output = line.strip('\\n').split('|', maxsplit=1)\n",
    "            if re.search(r'[$%BCDEFGHIJKLMNOPQRSTUVWXYabcdeghiklmnoprstuwy¥�]', line):\n",
    "                filenames.append(filenames)\n",
    "                asr_outputs.append(asr_output)\n",
    "    df = pd.DataFrame({'filename': filenames, 'asr_output': asr_outputs})\n",
    "    df.to_csv(str(asr_result_path) + '.csv', sep='|', index=False)\n",
    "    return df\n",
    " \n",
    "write_nonhans(gt_asr_path)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m     df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;28mstr\u001B[39m(asr_result_path) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m---> 14\u001B[0m \u001B[43mwrite_nonhans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgt_asr_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[42], line 11\u001B[0m, in \u001B[0;36mwrite_nonhans\u001B[0;34m(asr_result_path)\u001B[0m\n\u001B[1;32m      9\u001B[0m             asr_outputs\u001B[38;5;241m.\u001B[39mappend(asr_output)\n\u001B[1;32m     10\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfilename\u001B[39m\u001B[38;5;124m'\u001B[39m: filenames, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124masr_output\u001B[39m\u001B[38;5;124m'\u001B[39m: asr_outputs})\n\u001B[0;32m---> 11\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43masr_result_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m|\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[0;32m~/miniconda3/envs/whisper/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    328\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    329\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    330\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    331\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    332\u001B[0m     )\n\u001B[0;32m--> 333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/whisper/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[1;32m   3956\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[1;32m   3958\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[1;32m   3959\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[1;32m   3960\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3964\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[1;32m   3965\u001B[0m )\n\u001B[0;32m-> 3967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3969\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3970\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3972\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3973\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3974\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3975\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3976\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3977\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3978\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3979\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3980\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3981\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3982\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3983\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3984\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/whisper/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[1;32m    993\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    995\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[1;32m    996\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[1;32m    997\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1012\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[1;32m   1013\u001B[0m )\n\u001B[0;32m-> 1014\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1016\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[1;32m   1017\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[0;32m~/miniconda3/envs/whisper/lib/python3.10/site-packages/pandas/io/formats/csvs.py:270\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_handle(\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilepath_or_buffer,\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    258\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[1;32m    261\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[1;32m    262\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    267\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[1;32m    268\u001B[0m     )\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/whisper/lib/python3.10/site-packages/pandas/io/formats/csvs.py:275\u001B[0m, in \u001B[0;36mCSVFormatter._save\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_need_to_save_header:\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_header()\n\u001B[0;32m--> 275\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/whisper/lib/python3.10/site-packages/pandas/io/formats/csvs.py:313\u001B[0m, in \u001B[0;36mCSVFormatter._save_body\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m start_i \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m end_i:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 313\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_i\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/whisper/lib/python3.10/site-packages/pandas/io/formats/csvs.py:324\u001B[0m, in \u001B[0;36mCSVFormatter._save_chunk\u001B[0;34m(self, start_i, end_i)\u001B[0m\n\u001B[1;32m    321\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(res\u001B[38;5;241m.\u001B[39m_iter_column_arrays())\n\u001B[1;32m    323\u001B[0m ix \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_index[slicer]\u001B[38;5;241m.\u001B[39m_get_values_for_csv(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_number_format)\n\u001B[0;32m--> 324\u001B[0m \u001B[43mlibwriters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite_csv_rows\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m    \u001B[49m\u001B[43mix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnlevels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32mwriters.pyx:73\u001B[0m, in \u001B[0;36mpandas._libs.writers.write_csv_rows\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "def eval_cer(transcripts, asr_result_path, cer_path):\n",
    "    with open(cer_path, 'w') as cer_file:\n",
    "        cer_file.write('wav_file,hanzi_len,hanzi_cer,pinyin_len,pinyin_cer\\n')\n",
    "        with open(asr_result_path) as f:\n",
    "            for line in f:\n",
    "                wav_file, asr_hans = line.strip('\\n').split('|', maxsplit=1)\n",
    "                asr_hans = normalize_chinese(asr_hans)\n",
    "                asr_pinyins = ''.join(hans_to_pinyins(asr_hans)) \n",
    "                # eng_chars = sum([word.isascii() for word in asr_output])\n",
    "                hans, pinyins = transcripts[wav_file]\n",
    "                pinyins = re.sub(r'\\s', '', pinyins)\n",
    "                hanzi_len = len(hans)\n",
    "                pinyin_len = len(pinyins)\n",
    "                hanzi_cer = jiwer.cer(reference=hans, hypothesis=asr_hans)\n",
    "                pinyin_cer = jiwer.cer(reference=pinyins, hypothesis=asr_pinyins)\n",
    "                cer_file.write(f'{wav_file},{hanzi_len},{hanzi_cer},{pinyin_len},{pinyin_cer}\\n')\n",
    "                "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T06:14:10.546596Z",
     "start_time": "2024-07-15T06:14:10.541003Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "jets_cer_path = asr_dir / 'jets_cer.csv'\n",
    "eval_cer(transcripts=transcripts, asr_result_path=jets_asr_path, cer_path=jets_cer_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T06:15:49.866559Z",
     "start_time": "2024-07-15T06:15:43.018165Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "nopitch_cer_path = asr_dir / 'nopitch_cer.csv'\n",
    "eval_cer(transcripts=transcripts, asr_result_path=nopitch_asr_path, cer_path=nopitch_cer_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T18:36:17.144717871Z",
     "start_time": "2023-09-28T18:36:16.465948699Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline_cer_path = asr_dir / 'baseline_cer.csv'\n",
    "eval_cer(transcripts=transcripts, asr_result_path=baseline_asr_path, cer_path=baseline_cer_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gt_cer_path = asr_dir / 'gt_cer.csv'\n",
    "eval_cer(transcripts=transcripts, asr_result_path=gt_asr_path, cer_path=gt_cer_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T06:14:18.349207Z",
     "start_time": "2024-07-15T06:14:12.644089Z"
    }
   },
   "outputs": [],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
