{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "It's better to have Whisper in a separate environment from ESPnet. Also, we use `faster-whisper` as it is not only faster but more stable than the original.\n",
    "```shell\n",
    "conda create -n whisper python=3.10\n",
    "conda activate whisper\n",
    "pip install faster-whisper\n",
    "```\n",
    "before running this.\n",
    "\n",
    "You also need to set the env variable LD_LIBRARY_PATH:\n",
    "\n",
    "```shell\n",
    "conda activate whisper\n",
    "env_loc=$(conda env list | grep '*' | awk '{print $3}' | tr -d '\\n')\n",
    "activator=\"${env_loc}/etc/conda/activate.d/cuda_activate.sh\"\n",
    "echo export LD_LIBRARY_PATH=`python3 -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; import torch; print(os.path.dirname(nvidia.cublas.lib.__file__) + \":\" + os.path.dirname(nvidia.cudnn.lib.__file__) + \":\" + os.path.dirname(torch.__file__) +\"/lib\")'` > \"${activator}\"\n",
    "chmod +x \"${activator}\"\n",
    "conda deactivate\n",
    "conda activate whisper\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import faster_whisper\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "import re\n",
    "\n",
    "PWD = %pwd\n",
    "PWD = Path(PWD)\n",
    "prosody_dir = PWD.parent\n",
    "outputs_dir = PWD / 'outputs'\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "asr_dir = outputs_dir / 'CSS10' / 'german'\n",
    "os.makedirs(asr_dir, exist_ok=True)\n",
    "jets_dir = prosody_dir / 'outputs' / 'tts_train_jets_raw_phn_tacotron_g2p_en_no_space/CSS10/german'\n",
    "data_dir = (prosody_dir / '../../datasets/CSS10/german/').resolve()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T13:56:21.422335Z",
     "start_time": "2024-07-20T13:56:20.045551Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T16:46:25.659032Z",
     "start_time": "2024-06-19T16:46:25.654402Z"
    }
   },
   "cell_type": "code",
   "source": "faster_whisper.available_models()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large-v1',\n",
       " 'large-v2',\n",
       " 'large-v3',\n",
       " 'large']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T19:47:17.032120Z",
     "start_time": "2024-07-19T19:47:17.029836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "ld_lib_path = os.environ['LD_LIBRARY_PATH']\n",
    "assert 'cublas' in ld_lib_path and 'cudnn' in ld_lib_path"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T13:56:46.200202Z",
     "start_time": "2024-07-20T13:56:46.196883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = faster_whisper.WhisperModel(\"large-v2\", device='cuda', compute_type='float16')\n",
    "asr_dir = asr_dir / 'large-v2'\n",
    "os.makedirs(asr_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "german_letters = set()\n",
    "with open(data_dir / 'transcript.txt') as f:\n",
    "    for line in f:\n",
    "        german_letters |= set(line.split('|')[2].lower())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T17:08:43.554379Z",
     "start_time": "2024-06-19T17:08:43.507026Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T17:08:55.031206Z",
     "start_time": "2024-06-19T17:08:55.026912Z"
    }
   },
   "cell_type": "code",
   "source": "''.join(sorted(german_letters))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" !',-.:;?abcdefghijklmnopqrstuvwxyzßàäéöü–\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T19:55:15.282401Z",
     "start_time": "2024-07-19T19:55:15.278230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_german(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[!',-.:;?–]\", ' ', text)\n",
    "    text = text.replace('é', 'e')\n",
    "    text = text.replace('à', 'a')\n",
    "    text = re.sub(r'[^abcdefghijklmnopqrstuvwxyzßäöü ]', '', text)\n",
    "    text = ' '.join(text.strip().split())\n",
    "    # text = text.replace('ß', 'ss')\n",
    "    # normalize umlauts?\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T13:56:23.773388Z",
     "start_time": "2024-07-20T13:56:23.764303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transcript_file = data_dir / 'transcript_normalized.txt'\n",
    "if not transcript_file.exists():\n",
    "    with open(data_dir / 'transcript.txt') as f:\n",
    "        with open(transcript_file, 'w') as norm_f:\n",
    "            for line in f:\n",
    "                filename, _, transcript, _ = line.split('|')\n",
    "                transcript = normalize_german(transcript)\n",
    "                norm_f.write(f'{filename}|{transcript}\\n')\n",
    "\n",
    "\n",
    "def get_transcripts():\n",
    "    transcripts = {}\n",
    "    with open(transcript_file) as f:\n",
    "        for line in f:\n",
    "            filename, transcript = line.strip().split('|', maxsplit=1)\n",
    "            transcripts[filename] = transcript\n",
    "    return transcripts\n",
    "\n",
    "transcripts = get_transcripts()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T19:55:18.480272Z",
     "start_time": "2024-07-19T19:55:18.476308Z"
    }
   },
   "cell_type": "code",
   "source": "filenames = list(transcripts.keys())",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T19:55:19.006517Z",
     "start_time": "2024-07-19T19:55:19.003136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "whisper_kwargs = {\n",
    "    # 'suppress_tokens': suppress_tokens,\n",
    "    # 'temperature': 0.0,\n",
    "    # 'condition_on_previous_text': False,\n",
    "    'prepend_punctuations': '',\n",
    "    'append_punctuations': '',\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T20:06:25.435980Z",
     "start_time": "2024-07-19T20:06:25.430901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from num2words import num2words\n",
    "import numpy as np\n",
    "def whisper_transcribe(filepath, kwargs=whisper_kwargs):\n",
    "    segments, _ = model.transcribe(filepath, language='de', **kwargs)\n",
    "    text = ' '.join(segment.text for segment in segments)\n",
    "    pads = 1\n",
    "    while not text:  # whisper sometimes randomly fails to produce anything\n",
    "        audio = faster_whisper.audio.decode_audio(filepath)\n",
    "        audio_pad = np.pad(audio, (pads * 100, 0), mode='constant', constant_values=0)\n",
    "        segments, _ = model.transcribe(audio_pad, language='de', **kwargs)\n",
    "        text = ' '.join(segment.text for segment in segments)\n",
    "        pads += 1\n",
    "        if pads == 10:\n",
    "            break\n",
    "    splits = re.split(r'(\\d+)', text)\n",
    "    for i in range(len(splits)):\n",
    "        integer = splits[i] \n",
    "        if re.fullmatch(r'\\d+', integer):\n",
    "            word = num2words(integer, lang='de')\n",
    "            if re.fullmatch(r'100+', integer) and word.startswith('ein'):\n",
    "                word = word[3:]  # remove ein\n",
    "            splits[i] = word \n",
    "    text = ''.join(splits)\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T20:06:26.511910Z",
     "start_time": "2024-07-19T20:06:26.011769Z"
    }
   },
   "cell_type": "code",
   "source": "whisper_transcribe(data_dir / filenames[176])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Aber die hundert Segel, die jetzt von Jabarze kommen, zeigen in den Segelfalten keine Schriftzeichen mehr.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T20:06:35.474887Z",
     "start_time": "2024-07-19T20:06:35.471004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_asr(filenames, audio_dir, asr_result_path):\n",
    "    with open(asr_result_path, 'w') as f:\n",
    "        for filename in tqdm(filenames):\n",
    "            wav_path = audio_dir / filename\n",
    "            text = whisper_transcribe(wav_path)\n",
    "            text = normalize_german(text)\n",
    "            f.write(f'{filename}|{text}\\n')"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T18:33:01.280862Z",
     "start_time": "2024-07-02T18:33:01.277618Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "gt_dir = data_dir\n",
    "gt_asr_path = asr_dir / 'gt_result.txt'\n",
    "\n",
    "jets_asr_path = asr_dir / 'jets_result.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T13:56:52.407151Z",
     "start_time": "2024-07-20T13:56:52.404147Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "run_asr(filenames, gt_dir, gt_asr_path)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T21:14:35.887149Z",
     "start_time": "2024-07-19T20:06:41.502507Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7427/7427 [1:07:54<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "run_asr(filenames, jets_dir, jets_asr_path)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T22:22:10.131684Z",
     "start_time": "2024-07-19T21:14:35.888450Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7427/7427 [1:07:34<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "def eval_cer(transcripts, asr_result_path, cer_path):\n",
    "    with open(cer_path, 'w') as cer_file:\n",
    "        cer_file.write('wav_file,gt_len,cer\\n')\n",
    "        with open(asr_result_path) as f:\n",
    "            for line in f:\n",
    "                wav_file, asr_output = line.strip('\\n').split('|', maxsplit=1)\n",
    "                transcript = transcripts[wav_file]\n",
    "                transcript_nospace = transcript.replace(' ', '')\n",
    "                asr_nospace = asr_output.replace(' ', '')\n",
    "                gt_len = len(transcript)\n",
    "                cer = jiwer.cer(truth=transcript_nospace, hypothesis=asr_nospace)\n",
    "                cer_file.write(f'{wav_file},{gt_len},{cer}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T13:56:57.839138Z",
     "start_time": "2024-07-20T13:56:57.836118Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T22:22:10.513609Z",
     "start_time": "2024-07-19T22:22:10.140500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gt_cer_path = asr_dir / 'gt_cer.csv'\n",
    "eval_cer(transcripts=transcripts, asr_result_path=gt_asr_path, cer_path=gt_cer_path)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "jets_cer_path = asr_dir / 'jets_cer.csv'\n",
    "eval_cer(transcripts=transcripts, asr_result_path=jets_asr_path, cer_path=jets_cer_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T13:56:59.073906Z",
     "start_time": "2024-07-20T13:56:58.509891Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
